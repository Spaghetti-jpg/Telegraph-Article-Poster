###Maybe I'm Grey? Never mind###

import requests
from bs4 import BeautifulSoup
import vk_api
import json
from telegraph import Telegraph, exceptions as telegraph_exceptions
from urllib.parse import unquote
import time
import random

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
vk_api_key = ''
TELEGRAPH_API_KEY = ""
TELEGRAPH_AUTHOR_NAME = ""
TELEGRAPH_AUTHOR_URL = ""

TELEGRAM_API_KEY = ""
TELEGRAM_API_URL = "" + TELEGRAM_API_KEY
TELEGRAM_CHANNEL_ID = ""
TELEGRAM_SEND_METHOD = "/sendMessage"
TELEGRAM_POST_URL = TELEGRAM_API_URL + TELEGRAM_SEND_METHOD
 
GROUP_ID = ""
GROUP_SHORT_NAME = ""

vk_session = vk_api.VkApi(token=vk_api_key)
vk = vk_session.get_api()
telegraph = Telegraph(TELEGRAPH_API_KEY)

def get_link(vk):
    # –ü–æ–ª—É—á–µ–Ω–∏–µ 20 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø–æ—Å—Ç–æ–≤
    response = vk.wall.get(owner_id=GROUP_ID, count=20, filter='owner', extended=0)

    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å—Ç–∞—Ç—å–∏ –∏ –æ–ø–∏—Å–∞–Ω–∏–π –ø–æ—Å—Ç–æ–≤
    links = []
    descriptions = []
    for item in response['items']:
        # –ü—Ä–æ–ø—É—Å–∫ —Ä–µ–∫–ª–∞–º–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
        if item.get('marked_as_ads') == 1:
            continue
        if 'attachments' in item:
            for attachment in item['attachments']:
                if attachment['type'] == 'link':
                    url = attachment['link']['url']
                    if "https://m.vk.com/@{GROUP_SHORT_NAME}" in url:
                        links.append(url)
                        descriptions.append(item['text'])
    return links, descriptions

def get_html_content(link):
    # –ü–æ–ª—É—á–µ–Ω–∏–µ HTML-–∫–æ–¥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    response = requests.get(link)
    
    soup = BeautifulSoup(response.text, 'html.parser')

    ALLOWED_TAGS = [
        'a', 'aside', 'b', 'blockquote', 'br', 'code', 'em', 'figcaption', 'figure',
        'h3', 'h4', 'hr', 'i', 'iframe', 'img', 'li', 'ol', 'p', 'pre', 's',
        'strong', 'u', 'ul', 'video'
    ]

    def filter_allowed_tags(soup, allowed_tags):
        tags = []
        for tag in soup.find_all(allowed_tags):
            if tag not in tags and not any(str(tag) in str(t) for t in tags if t != tag):
                for inner_tag in tag.find_all():
                    if inner_tag.name not in allowed_tags:
                        inner_tag.unwrap()
                tags += [tag]
        return tags
        
    for img in soup.find_all('div', class_="article_object_sizer_wrap"):
        img.find('img')['src'] = json.loads(img.attrs['data-sizes'])[0]['x'][0]

    # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö div —Å –∫–ª–∞—Å—Å–æ–º "article__info_line"
    for div in soup.find_all('div', class_="article__info_line"):
        div.decompose()

    # –ó–∞–º–µ–Ω–∞ —Å—Å—ã–ª–æ–∫, —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö "/away.php?to="
    for a in soup.find_all('a', href=True):
        if "/away.php?to=" in a['href']:
            a['href'] = unquote(a['href'].replace("/away.php?to=", ""))

    article_div = soup.find("div", {"class": "article_view"})
    article_title = soup.find("h1").text

    arr = filter_allowed_tags(article_div, ALLOWED_TAGS)

    result = soup.new_tag("div")

    for el in arr:
        result.append(el)

    return (article_title, result.prettify())

def post_article_telegraph(article, link, description):
    source = article[1]
    source = source.replace("<div>", "").replace("</div>", "")
    try:
        response = telegraph.create_page(
            article[0],
            html_content=source,
            author_name=TELEGRAPH_AUTHOR_NAME,
            author_url=TELEGRAPH_AUTHOR_URL
        )
        print(f"\n–û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –ø–æ —Å—Å—ã–ª–∫–µ: {response['url']}")
        # –ó–∞–ø–∏—Å—å —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç–∞—Ç—å—é –∏ URL —Å—Ç–∞—Ç—å–∏ –≤ Telegraph –≤ —Ñ–∞–π–ª
        with open('post.txt', 'a', encoding='utf-8') as f:
            f.write(link + '\n' + response['url'] + '\n')
        time.sleep(2)  # –ü–∞—É–∑–∞ –≤ 2 —Å–µ–∫—É–Ω–¥—ã
        # –û—Ç–ø—Ä–∞–≤–∫–∞ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç–∞—Ç—å—é –≤ —Ç–µ–ª–µ–≥—Ä–∞—Ñ –≤ –≥—Ä—É–ø–ø—É –≤ —Ç–µ–ª–µ–≥—Ä–∞–º
        post_article_telegram(response['url'], description)
        return response['url']
    except Exception as e:
        print(f"Error: {e}")
        if "CONTENT_TOO_BIG" in str(e):
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ {link}, CONTENT_TOO_BIG")
            # –ó–∞–ø–∏—Å—å —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç–∞—Ç—å—é VK –≤ —Ñ–∞–π–ª, –¥–∞–∂–µ –µ—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –æ—à–∏–±–∫–∞ CONTENT_TOO_BIG
            with open('post.txt', 'a', encoding='utf-8') as f:
                f.write(link + '\n')
            return "CONTENT_TOO_BIG"
        else:
            raise Exception("Telegram Post Publication Err")

def post_article_telegram(text, description):
    description = description.replace('@{GROUP_SHORT_NAME}', '')
    r = requests.post(url=TELEGRAM_POST_URL, json={
        "chat_id": TELEGRAM_CHANNEL_ID,
        "text": description + '\n\n' + text,  # –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–∏ –º–µ–∂–¥—É –æ–ø–∏—Å–∞–Ω–∏–µ–º –∏ —Å—Å—ã–ª–∫–æ–π
        "link_preview_options": {
            "prefer_large_media": True,  # –£–≤–µ–ª–∏—á–µ–Ω–Ω–æ–µ –º–µ–¥–∏–∞ –≤ –ø—Ä–µ–≤—å—é —Å—Å—ã–ª–æ–∫
            "prefer_small_media": False,
            "is_disabled": False
        }
    })
    time.sleep(2)  # –ü–∞—É–∑–∞ –≤ 2 —Å–µ–∫—É–Ω–¥—ã
    if r.status_code != 200:
        raise Exception("Telegram Post Publication Err")
 
    message_id = r.json()["result"]["message_id"] # –ü–æ–ª—É—á–µ–Ω–∏–µ ID –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    reactions = ["‚ù§", "üëç", "üî•"] # –°–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Ä–µ–∞–∫—Ü–∏–π
    reaction = random.choice(reactions) # –í—ã–±–æ—Ä —Å–ª—É—á–∞–π–Ω–æ–π —Ä–µ–∞–∫—Ü–∏–∏ –∏–∑ —Å–ø–∏—Å–∫–∞

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∞–∫—Ü–∏–∏ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ
    reaction_url = TELEGRAM_API_URL + "/setMessageReaction"
    response = requests.post(url=reaction_url, json={
        "chat_id": TELEGRAM_CHANNEL_ID,
        "message_id": message_id,
        "reaction": [{"type": "emoji", "emoji": reaction}],
    })

    print(f"\n–°—Ç–∞—Ç—å—è –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º:\n {description}")

if __name__ == "__main__":
    links, descriptions = get_link(vk)
    for link, description in zip(links, descriptions):
        # –ü—Ä–æ–≤–µ—Ä–∫–∞, –µ—Å—Ç—å –ª–∏ —Å—Å—ã–ª–∫–∞ —É–∂–µ –≤ —Ñ–∞–π–ª–µ
        with open('post.txt', 'a+', encoding='utf-8') as f:
            f.seek(0)  # –ø–µ—Ä–µ–º–µ—â–∞–µ–º —É–∫–∞–∑–∞—Ç–µ–ª—å –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ —á—Ç–µ–Ω–∏–µ–º
            if link not in f.read():
                article_title, html_content = get_html_content(link)
                # –ï—Å–ª–∏ html_content —Ä–∞–≤–Ω–æ None, –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ç—É –∏—Ç–µ—Ä–∞—Ü–∏—é —Ü–∏–∫–ª–∞
                if html_content is None:
                    continue
                # –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ Telegraph
                post_article_telegraph((article_title, html_content), link, description)

